{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D, Input, Flatten, Dropout, Activation,  Dense, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import yaml\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# PATHS\n",
    "base = ''\n",
    "features_fp = os.path.join(base, 'training_X_power.npy')\n",
    "labels_fp = os.path.join(base, 'sample_class.csv')\n",
    "config_fp = os.path.join(base, 'config_power.yaml')\n",
    "\n",
    "# DATA\n",
    "features = np.load(features_fp)\n",
    "labels = pd.read_csv(labels_fp, delimiter=\",\", index_col=0)\n",
    "\n",
    "def find_on_effects(path):\n",
    "    effects = yaml.load(open(path, 'r'))\n",
    "    used = effects.get('DataAugmentation')\n",
    "    active = used.get('active')\n",
    "    sustain = used.get('sustain')\n",
    "    r = used.get('effects')\n",
    "    random_subeffects = [[k for k,v in r.get(a).items() if v.get('state') == 'random'] for a in active]\n",
    "    return {a: random_subeffects[ix] for ix, a in enumerate(active)}, active, sustain\n",
    "\n",
    "def one_hot_binarize(labels, predict_effects):\n",
    "    \n",
    "    abbrv = [x.split('.') for x in predict_effects]\n",
    "    abbrv = [(x[0][:2] + '.' + x[-1][:2]).upper() for x in abbrv]\n",
    "    binarize = labels[predict_effects].fillna(0)\n",
    "    binarize = binarize.where(binarize == 0).replace(np.nan, 1)\n",
    "    def labelize(row, abbrv):\n",
    "        return ':__'.join(e + str(int(r)) for e,r in zip(abbrv, list(tuple(row))))\n",
    "    labels = binarize.apply(lambda x: labelize(x, abbrv), axis = 1)\n",
    "    encoder = LabelEncoder()\n",
    "    one_hot = np_utils.to_categorical(encoder.fit_transform(labels))\n",
    "    states = list(encoder.classes_)\n",
    "    return one_hot, states\n",
    "\n",
    "def format_data(config = config_fp, predicted_effects = ['overdrive.gain_db', \n",
    "                                                         'reverb.reverberance', \n",
    "                                                         'chorus.delays'] ):\n",
    "    \n",
    "    random_fx, active, sustain = find_on_effects(config_fp)\n",
    "    print ('Active effects: {}'.format(active))\n",
    "    print ('Persisting {} during augmentation'.format(sustain))\n",
    "    print ('Parameters allowed randomization {}'.format(random_fx))\n",
    "    # Ideally generate effects\n",
    "    print ('Effects to predict {}'.format(predicted_effects))\n",
    "    binarized_y, states = one_hot_binarize(labels = globals()['labels'], predict_effects = predict_effects)\n",
    "    [*data] = train_test_split(globals()['features'],binarized_y, shuffle = True, test_size = 0.2, random_state = 44)\n",
    "    shapes = list(map(lambda x: x.shape, data))\n",
    "    return data, shapes, states\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAKE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active effects: ['overdrive', 'reverb', 'chorus', 'phaser']\n",
      "Persisting ['groko'] during augmentation\n",
      "Parameters allowed randomization {'overdrive': ['gain_db'], 'reverb': ['reverberance'], 'chorus': [], 'phaser': []}\n",
      "Effects to predict ['overdrive.gain_db', 'reverb.reverberance', 'chorus.delays']\n"
     ]
    }
   ],
   "source": [
    "data, shapes, states = format_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_10: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-369e20e9012e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.add(Conv1D(128, 5,padding='same',\n\u001b[0;32m----> 7\u001b[0;31m                  input_shape=X_train[0].shape[1:]))\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    164\u001b[0m                     \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                     \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                     \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m                     \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_10: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# NOT USING FUNCTIONAL ARCHITECTURE YET\n",
    "\n",
    "# SAMPLE ARCHITECTURE\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',\n",
    "                 input_shape=X_train[0].shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPooling1D(pool_size=(8)))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(model)\n",
    "# USING BINARIZER CLASSES\n",
    "model2.add(Dense(len(states), activation = \"softmax\"))\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(model)\n",
    "model1.add(Dense(1, activation = \"relu\"))\n",
    "\n",
    "opt = opt = keras.optimizers.Adam(lr=0.00001)\n",
    "\n",
    "model1.compile(optimizer= opt, loss=['mae'], metrics =[\"mae\"])\n",
    "model2.compile(optimizer = opt, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
